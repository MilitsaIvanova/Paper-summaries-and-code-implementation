{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c71b36",
   "metadata": {},
   "source": [
    "# Summary of the article \"Breast Cancer Classification using Random Forest Algorithm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6394f0c7",
   "metadata": {},
   "source": [
    "The article titled \"Breast Cancer Classification using Random Forest Algorithm,\" published in the Journal of Physics: Conference Series, focuses on utilizing the Random Forest (RF) algorithm for diagnosing breast cancer, reducing variance and boosting accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281bd10a",
   "metadata": {},
   "source": [
    "They have provided the following diagram  of the workflow: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734903a4",
   "metadata": {},
   "source": [
    "<img src='workflow.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66876713",
   "metadata": {},
   "source": [
    "The methodology includes data collection and analysis, feature standardization and decomposition, and training/testing data preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52b5c54",
   "metadata": {},
   "source": [
    "The dataset used for this research is the Wisconsin diagnostic breast cancer (WBDC dataset, available from the UCI Machine Learning Repository). The dataset has 569 samples of nuclei and 32 features. They have divided the data in train/test split as follows: 70% / 30%. The training set is further divided into k subset and a k-fold cross-validation is performed (k = 10). This is to ensure robustness and avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d87ff60",
   "metadata": {},
   "source": [
    "The classifier used is the Random Forest classifier from scikitlearn. They refer to other researches that show that the RF tree is more efficient in the low number of data samples. They claim that RF is not affected by noise. A key reason would be RF's ability to manage data minorities. They claim that it is possible to classify tumor as benign or malignant, except that the latter class accounts for just 10% of all input data.\n",
    "\n",
    "They also use the KNIME node Tree Ensemble Learner to compare the results of the two methods. The Tree Ensemble Learner in KNIME is a component used for building ensemble models based on decision trees, such as Random Forests. This learner combines multiple decision trees to create a more robust and accurate model. Each tree in the ensemble is trained on a random subset of the data, and their predictions are aggregated (through voting for classification or averaging for regression) to produce the final output. This approach helps in reducing overfitting, improving model accuracy, and handling large datasets effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe806266",
   "metadata": {},
   "source": [
    "The model evaluation is done using AUC (Area under the curve), Accuracy, F1 score and Sensitivity as measures. \n",
    "- AUC is the area under the ROC curve. This curve plots the True positives against the False positives. A higher AUC represents better model performance\n",
    "- Accuracy is the sum of True positives and True negatives divided by the total number of cases examined. This measure can be misleading in cases of imbalanced classes (such as here).\n",
    "- F1 score is the harmonic mean of Precision and Recall. This measure is useful when there are imbalanced classes.\n",
    "- Sensitivity (a.k.a Recall) measures the proportion of actual positives that are correctly identified as such. Important in medical testing or other diagnostic tests where missing out on positives is particularly costly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba64c0e7",
   "metadata": {},
   "source": [
    "The results are comparing the performance of the Random Forest algorithm to the KNIME node Tree Ensemble Learner: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc44ac8b",
   "metadata": {},
   "source": [
    "<img src='model_evaluation.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafdf93d",
   "metadata": {},
   "source": [
    "<img src='evaluation2.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f6db39",
   "metadata": {},
   "source": [
    "We can see that Random Forest excels in every metric compared to the KNIME node Tree Ensemble Learner. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762140ca",
   "metadata": {},
   "source": [
    "The main contribution of the paper is its demonstration of the effectiveness of the RF algorithm in classifying breast cancer, providing a more precise and dependable diagnostic tool than conventional techniques.\n",
    "It draws attention to the potential benefits of machine learning in healthcare, especially in terms of enhancing patient safety and diagnostic precision.\n",
    "The approach and findings provide a valuable reference for future investigations into machine learning-based medical diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d61d08",
   "metadata": {},
   "source": [
    "# Code reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e76e25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f7eb8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79aab5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "458d3a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65a7e81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  target                   569 non-null    int32  \n",
      "dtypes: float64(30), int32(1)\n",
      "memory usage: 135.7 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c904f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets (70% training, 30% testing)\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d62001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5767d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier with 10-fold cross-validation\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "rf_classifier = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "952380fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to store evaluation metrics\n",
    "accuracy_scores = []\n",
    "auc_scores = []\n",
    "f1_scores = []\n",
    "sensitivity_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70c04a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross-Validation\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7159aad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "rf_classifier.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "# Making predictions\n",
    "y_val_pred = rf_classifier.predict(X_val_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd865f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
    "auc = roc_auc_score(y_val_fold, y_val_pred)\n",
    "report = classification_report(y_val_fold, y_val_pred, output_dict=True)\n",
    "f1 = report['weighted avg']['f1-score']\n",
    "sensitivity = report['1']['recall']  # Sensitivity for the '1' class (malignant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05a320a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores.append(accuracy)\n",
    "auc_scores.append(auc)\n",
    "f1_scores.append(f1)\n",
    "sensitivity_scores.append(sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79bb0360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating average scores across all folds\n",
    "avg_accuracy = np.mean(accuracy_scores)\n",
    "avg_auc = np.mean(auc_scores)\n",
    "avg_f1 = np.mean(f1_scores)\n",
    "avg_sensitivity = np.mean(sensitivity_scores)\n",
    "\n",
    "avg_accuracy, avg_auc, avg_f1, avg_sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ae80125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9707602339181286\n",
      "AUC: 0.9669312169312169\n",
      "F1-score: 0.9707106475867088\n",
      "Recall (for the first class 'malignant'): 0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the testing set\n",
    "y_test_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics for testing set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_auc = roc_auc_score(y_test, y_test_pred)\n",
    "test_report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "test_f1 = test_report['weighted avg']['f1-score']\n",
    "test_sensitivity = test_report['1']['recall']\n",
    "\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"AUC: {test_auc}\")\n",
    "print(f\"F1-score: {test_f1}\")\n",
    "print(f\"Recall (for the first class 'malignant'): {test_sensitivity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb61007f",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e96b2d",
   "metadata": {},
   "source": [
    "<p style='font-size: 16px'>The results of reproducing the code are similar to those in the paper. The model has a high recall, for the class 'malignant', which means that it successfully captures the cases where there is a diseased cell which is very important for imbalanced datasets such as this one.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
